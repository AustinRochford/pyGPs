<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>pyGPs.Core.opt &mdash; pyGPs v1.2 documentation</title>
    
    <link rel="stylesheet" href="../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     'v1.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <link rel="top" title="pyGPs v1.2 documentation" href="../../../index.html" />
    <link rel="up" title="pyGPs.Core" href="../Core.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../../index.html">pyGPs v1.2 documentation</a> &raquo;</li>
          <li><a href="../../index.html" >Module code</a> &raquo;</li>
          <li><a href="../Core.html" accesskey="U">pyGPs.Core</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for pyGPs.Core.opt</h1><div class="highlight"><pre>
<span class="c">#================================================================================</span>
<span class="c">#    Marion Neumann [marion dot neumann at uni-bonn dot de]</span>
<span class="c">#    Daniel Marthaler [marthaler at ge dot com]</span>
<span class="c">#    Shan Huang [shan dot huang at iais dot fraunhofer dot de]</span>
<span class="c">#    Kristian Kersting [kristian dot kersting at cs dot tu-dortmund dot de]</span>
<span class="c">#</span>
<span class="c">#    This file is part of pyGPs.</span>
<span class="c">#    The software package is released under the BSD 2-Clause (FreeBSD) License.</span>
<span class="c">#</span>
<span class="c">#    Copyright (c) by</span>
<span class="c">#    Marion Neumann, Daniel Marthaler, Shan Huang &amp; Kristian Kersting, 18/02/2014</span>
<span class="c">#================================================================================</span>

<span class="c"># This is a object-oriented python implementation of gpml functionality </span>
<span class="c"># (Copyright (c) by Carl Edward Rasmussen and Hannes Nickisch, 2011-02-18).</span>
<span class="c"># based on the functional-version of python implementation</span>
<span class="c"># (Copyright (c) by Marion Neumann and Daniel Marthaler, 20/05/2013)</span>
<span class="c"># </span>
<span class="c"># Copyright (c) by Marion Neumann and Shan Huang, 30/09/2013</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_bfgs</span> <span class="k">as</span> <span class="n">bfgs</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_cg</span> <span class="k">as</span> <span class="n">cg</span>
<span class="kn">from</span> <span class="nn">..Optimization</span> <span class="kn">import</span> <span class="n">minimize</span><span class="p">,</span> <span class="n">scg</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="k">class</span> <span class="nc">Optimizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">nlml</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Find negative-log-marginal-likelihood&#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_in_objects</span><span class="p">(</span><span class="n">hypInArray</span><span class="p">)</span>
        <span class="n">nlZ</span><span class="p">,</span> <span class="n">dnlZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">der</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nlZ</span>

    <span class="k">def</span> <span class="nf">dnlml</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Find derivatives wrt. negative-log-marginal-likelihood&#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_in_objects</span><span class="p">(</span><span class="n">hypInArray</span><span class="p">)</span>
        <span class="n">nlZ</span><span class="p">,</span> <span class="n">dnlZ</span><span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">dnlml_List</span> <span class="o">=</span> <span class="n">dnlZ</span><span class="o">.</span><span class="n">mean</span> <span class="o">+</span> <span class="n">dnlZ</span><span class="o">.</span><span class="n">cov</span> <span class="o">+</span> <span class="n">dnlZ</span><span class="o">.</span><span class="n">lik</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dnlml_List</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">nlzAnddnlz</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Find negative-log-marginal-likelihood and derivatives in one pass(faster)&#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_in_objects</span><span class="p">(</span><span class="n">hypInArray</span><span class="p">)</span>
        <span class="n">nlZ</span><span class="p">,</span> <span class="n">dnlZ</span><span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">dnlml_List</span> <span class="o">=</span> <span class="n">dnlZ</span><span class="o">.</span><span class="n">mean</span> <span class="o">+</span> <span class="n">dnlZ</span><span class="o">.</span><span class="n">cov</span> <span class="o">+</span> <span class="n">dnlZ</span><span class="o">.</span><span class="n">lik</span>
        <span class="k">return</span> <span class="n">nlZ</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dnlml_List</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">convert_to_array</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Convert all hyparameters in the model to an array&#39;&#39;&#39;</span>
        <span class="n">hyplist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">meanfunc</span><span class="o">.</span><span class="n">hyp</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">covfunc</span><span class="o">.</span><span class="n">hyp</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">likfunc</span><span class="o">.</span><span class="n">hyp</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hyplist</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply_in_objects</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Apply the values in the input array to hyparameters of model.&#39;&#39;&#39;</span>
        <span class="n">Lm</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">meanfunc</span><span class="o">.</span><span class="n">hyp</span><span class="p">)</span>
        <span class="n">Lc</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">covfunc</span><span class="o">.</span><span class="n">hyp</span><span class="p">)</span>
        <span class="n">hypInList</span> <span class="o">=</span> <span class="n">hypInArray</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">meanfunc</span><span class="o">.</span><span class="n">hyp</span>  <span class="o">=</span> <span class="n">hypInList</span><span class="p">[:</span><span class="n">Lm</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">covfunc</span><span class="o">.</span><span class="n">hyp</span>   <span class="o">=</span> <span class="n">hypInList</span><span class="p">[</span><span class="n">Lm</span><span class="p">:(</span><span class="n">Lm</span><span class="o">+</span><span class="n">Lc</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">likfunc</span><span class="o">.</span><span class="n">hyp</span>   <span class="o">=</span> <span class="n">hypInList</span><span class="p">[(</span><span class="n">Lm</span><span class="o">+</span><span class="n">Lc</span><span class="p">):]</span>

       

<div class="viewcode-block" id="CG"><a class="viewcode-back" href="../../../Graph.html#pyGPs.Core.opt.CG">[docs]</a><span class="k">class</span> <span class="nc">CG</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Conjugent gradient&#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">searchConfig</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span> <span class="o">=</span> <span class="n">searchConfig</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">findMin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">meanfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">meanfunc</span>
        <span class="n">covfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">covfunc</span>
        <span class="n">likfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">likfunc</span>
        <span class="n">inffunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">inffunc</span>
        <span class="n">hypInArray</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_array</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlml</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnlml</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">opt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">warnFlag</span>   <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">warnFlag</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Maximum number of iterations exceeded.&quot;</span>
            <span class="k">elif</span> <span class="n">warnFlag</span> <span class="o">==</span>  <span class="mi">2</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Gradient and/or function calls not changing.&quot;</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>         
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Can not use conjugate gradient. Try other hyparameters&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>
            <span class="n">searchRange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">covRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">likRange</span> 
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Specify at least one of the stop conditions&#39;</span><span class="p">)</span>
            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>                 <span class="c"># increase counter</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">hypInArray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>   <span class="c"># random init of hyp</span>
                    <span class="n">hypInArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                <span class="c"># value this time is better than optiaml min value</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">thisopt</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlml</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnlml</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">funcValue</span><span class="p">:</span>
                        <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&quot;[CG] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Over half of the trails failed for conjugate gradient&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>         <span class="c"># if exceed num_restarts</span>
                    <span class="k">print</span> <span class="s">&quot;[CG] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span> <span class="ow">and</span> <span class="n">funcValue</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">:</span>           <span class="c"># reach provided mininal</span>
                    <span class="k">print</span> <span class="s">&quot;[CG] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span> 
        <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>


</div>
<div class="viewcode-block" id="BFGS"><a class="viewcode-back" href="../../../Graph.html#pyGPs.Core.opt.BFGS">[docs]</a><span class="k">class</span> <span class="nc">BFGS</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;quasi-Newton method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS)&#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">searchConfig</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BFGS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span> <span class="o">=</span> <span class="n">searchConfig</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">findMin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">meanfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">meanfunc</span>
        <span class="n">covfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">covfunc</span>
        <span class="n">likfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">likfunc</span>
        <span class="n">inffunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">inffunc</span>
        <span class="n">hypInArray</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_array</span><span class="p">()</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">bfgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlml</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnlml</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">opt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">warnFlag</span>   <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">warnFlag</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Maximum number of iterations exceeded.&quot;</span>
            <span class="k">elif</span> <span class="n">warnFlag</span> <span class="o">==</span>  <span class="mi">2</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Gradient and/or function calls not changing.&quot;</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>         
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Can not use BFGS. Try other hyparameters&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>
            <span class="n">searchRange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">covRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">likRange</span> 
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Specify at least one of the stop conditions&#39;</span><span class="p">)</span>
            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>                 <span class="c"># increase counter</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">hypInArray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>   <span class="c"># random init of hyp</span>
                    <span class="n">hypInArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                <span class="c"># value this time is better than optiaml min value</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">thisopt</span> <span class="o">=</span> <span class="n">bfgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlml</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnlml</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">funcValue</span><span class="p">:</span>
                        <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&quot;[BFGS] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Over half of the trails failed for BFGS&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>         <span class="c"># if exceed num_restarts</span>
                    <span class="k">print</span> <span class="s">&quot;[BFGS] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span> <span class="ow">and</span> <span class="n">funcValue</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">:</span>           <span class="c"># reach provided mininal</span>
                    <span class="k">print</span> <span class="s">&quot;[BFGS] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span> 

        <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>


</div>
<div class="viewcode-block" id="Minimize"><a class="viewcode-back" href="../../../Graph.html#pyGPs.Core.opt.Minimize">[docs]</a><span class="k">class</span> <span class="nc">Minimize</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;minimize by Carl Rasmussen (python implementation of &quot;minimize&quot; in GPML)&#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">searchConfig</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Minimize</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span> <span class="o">=</span> <span class="n">searchConfig</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">findMin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">meanfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">meanfunc</span>
        <span class="n">covfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">covfunc</span>
        <span class="n">likfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">likfunc</span>
        <span class="n">inffunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">inffunc</span>
        <span class="n">hypInArray</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_array</span><span class="p">()</span>

        <span class="k">try</span><span class="p">:</span> 
            <span class="n">opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlzAnddnlz</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">,</span> <span class="n">length</span><span class="o">=-</span><span class="mi">40</span><span class="p">)</span>
            <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">opt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>         
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Can not use minimize. Try other hyparameters&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>
            <span class="n">searchRange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">covRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">likRange</span> 
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Specify at least one of the stop conditions&#39;</span><span class="p">)</span>
            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>                 <span class="c"># increase counter</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">hypInArray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>   <span class="c"># random init of hyp</span>
                    <span class="n">hypInArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                <span class="c"># value this time is better than optiaml min value</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">thisopt</span> <span class="o">=</span> <span class="n">minimize</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlzAnddnlz</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">,</span> <span class="n">length</span><span class="o">=-</span><span class="mi">40</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">funcValue</span><span class="p">:</span>
                        <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&quot;[Minimize] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Over half of the trails failed for minimize&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>         <span class="c"># if exceed num_restarts</span>
                    <span class="k">print</span> <span class="s">&quot;[Minimize] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span> <span class="ow">and</span> <span class="n">funcValue</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">:</span>           <span class="c"># reach provided mininal</span>
                    <span class="k">print</span> <span class="s">&quot;[Minimize] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>                   
        <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>


</div>
<div class="viewcode-block" id="SCG"><a class="viewcode-back" href="../../../Graph.html#pyGPs.Core.opt.SCG">[docs]</a><span class="k">class</span> <span class="nc">SCG</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Scaled conjugent gradient (faster than CG)&#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">searchConfig</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SCG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span> <span class="o">=</span> <span class="n">searchConfig</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">findMin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">meanfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">meanfunc</span>
        <span class="n">covfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">covfunc</span>
        <span class="n">likfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">likfunc</span>
        <span class="n">inffunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">inffunc</span>
        <span class="n">hypInArray</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_to_array</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">scg</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlzAnddnlz</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">)</span>
            <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">opt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>         
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Can not use Scaled conjugate gradient. Try other hyparameters&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="p">:</span>
            <span class="n">searchRange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">covRange</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">likRange</span> 
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Specify at least one of the stop conditions&#39;</span><span class="p">)</span>
            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">+=</span> <span class="mi">1</span>                 <span class="c"># increase counter</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">hypInArray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>   <span class="c"># random init of hyp</span>
                    <span class="n">hypInArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="n">searchRange</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                <span class="c"># value this time is better than optiaml min value</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">thisopt</span> <span class="o">=</span> <span class="n">scg</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlzAnddnlz</span><span class="p">,</span> <span class="n">hypInArray</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">funcValue</span><span class="p">:</span>
                        <span class="n">funcValue</span>  <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">optimalHyp</span> <span class="o">=</span> <span class="n">thisopt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&quot;[SCG] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Over half of the trails failed for Scaled conjugate gradient&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">num_restarts</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>         <span class="c"># if exceed num_restarts</span>
                    <span class="k">print</span> <span class="s">&quot;[SCG] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span> <span class="ow">and</span> <span class="n">funcValue</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searchConfig</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">:</span>           <span class="c"># reach provided mininal</span>
                    <span class="k">print</span> <span class="s">&quot;[SCG] </span><span class="si">%d</span><span class="s"> out of </span><span class="si">%d</span><span class="s"> trails failed during optimization&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">errorCounter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trailsCounter</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span> 

        <span class="k">return</span> <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">funcValue</span>
</pre></div></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../../index.html">pyGPs v1.2 documentation</a> &raquo;</li>
          <li><a href="../../index.html" >Module code</a> &raquo;</li>
          <li><a href="../Core.html" >pyGPs.Core</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Marion Neumann, Shan Huang, Daniel Marthaler, Kristian Kersting.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.
    </div>
  </body>
</html>
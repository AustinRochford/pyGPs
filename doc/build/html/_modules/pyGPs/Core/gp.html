<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>pyGPs.Core.gp &mdash; pyGPs v1.3.2 documentation</title>
    
    <link rel="stylesheet" href="../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     'v1.3.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <link rel="top" title="pyGPs v1.3.2 documentation" href="../../../index.html" />
    <link rel="up" title="Module code" href="../../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../../index.html">pyGPs v1.3.2 documentation</a> &raquo;</li>
          <li><a href="../../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for pyGPs.Core.gp</h1><div class="highlight"><pre>
<span class="c">#================================================================================</span>
<span class="c">#    Marion Neumann [marion dot neumann at uni-bonn dot de]</span>
<span class="c">#    Daniel Marthaler [dan dot marthaler at gmail dot com]</span>
<span class="c">#    Shan Huang [shan dot huang at iais dot fraunhofer dot de]</span>
<span class="c">#    Kristian Kersting [kristian dot kersting at cs dot tu-dortmund dot de]</span>
<span class="c">#</span>
<span class="c">#    This file is part of pyGPs.</span>
<span class="c">#    The software package is released under the BSD 2-Clause (FreeBSD) License.</span>
<span class="c">#</span>
<span class="c">#    Copyright (c) by</span>
<span class="c">#    Marion Neumann, Daniel Marthaler, Shan Huang &amp; Kristian Kersting, 18/02/2014</span>
<span class="c">#================================================================================</span>

<span class="c">#   MEANING OF NOTATION:</span>
<span class="c">#</span>
<span class="c">#   inffunc      function specifying the inference method</span>
<span class="c">#   covfunc      prior covariance function (see below)</span>
<span class="c">#   meanfunc     prior mean function</span>
<span class="c">#   likfunc      likelihood function</span>
<span class="c">#   x            n by D matrix of training inputs</span>
<span class="c">#   y            column vector of length n of training targets</span>
<span class="c">#   xs           n by D matrix of test inputs</span>
<span class="c">#   ys           column vector of length nn of true test targets (optional)</span>
<span class="c">#   nlZ          returned value of the negative log marginal likelihood</span>
<span class="c">#   dnlZ         column vector of partial derivatives of the negative</span>
<span class="c">#                    log marginal likelihood w.r.t. each hyperparameter</span>
<span class="c">#   ym           column vector (of length ns) of predictive output means</span>
<span class="c">#   ys2          column vector (of length ns) of predictive output variances</span>
<span class="c">#   fm           column vector (of length ns) of predictive latent means</span>
<span class="c">#   fs2          column vector (of length ns) of predictive latent variances</span>
<span class="c">#   lp           column vector (of length ns) of log predictive probabilities</span>
<span class="c">#   post         struct representation of the (approximate) posterior</span>
<span class="c">#                post consists of post.alpha, post.L, post.sW</span>
<span class="c">#</span>
<span class="c"># This is a object-oriented python implementation of gpml functionality</span>
<span class="c"># (Copyright (c) by Carl Edward Rasmussen and Hannes Nickisch, 2011-02-18).</span>
<span class="c"># based on the functional-version of python implementation</span>
<span class="c"># (Copyright (c) by Marion Neumann and Daniel Marthaler, 20/05/2013)</span>
<span class="c">#</span>
<span class="c"># Copyright (c) by Marion Neumann and Shan Huang, 30/09/2013</span>

<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">inf</span><span class="o">,</span> <span class="nn">mean</span><span class="o">,</span> <span class="nn">lik</span><span class="o">,</span> <span class="nn">cov</span><span class="o">,</span> <span class="nn">opt</span>
<span class="kn">from</span> <span class="nn">tools</span> <span class="kn">import</span> <span class="n">unique</span><span class="p">,</span> <span class="n">jitchol</span><span class="p">,</span> <span class="n">solve_chol</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="nn">pyGPs</span>

<span class="n">SHADEDCOLOR</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.7539</span><span class="p">,</span> <span class="mf">0.89453125</span><span class="p">,</span> <span class="mf">0.62890625</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">MEANCOLOR</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.2109375</span><span class="p">,</span> <span class="mf">0.63385</span><span class="p">,</span> <span class="mf">0.1796875</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">DATACOLOR</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.12109375</span><span class="p">,</span> <span class="mf">0.46875</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">GP</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Base class for GP model.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="o">=</span> <span class="bp">True</span>  <span class="c"># was using default mean function now?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="bp">None</span>      <span class="c"># mean function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="bp">None</span>       <span class="c"># covariance function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="bp">None</span>       <span class="c"># likelihood function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="bp">None</span>       <span class="c"># inference function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="bp">None</span>     <span class="c"># optimizer object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nlZ</span> <span class="o">=</span> <span class="bp">None</span>           <span class="c"># negative log marginal likelihood</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dnlZ</span> <span class="o">=</span> <span class="bp">None</span>          <span class="c"># column vector of partial derivatives of the negative</span>
                                  <span class="c"># log marginal likelihood w.r.t. each hyperparameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span> <span class="o">=</span> <span class="bp">None</span>     <span class="c"># struct representation of the (approximate) posterior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>             <span class="c"># n by D matrix of training inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">None</span>             <span class="c"># column vector of length n of training targets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xs</span> <span class="o">=</span> <span class="bp">None</span>            <span class="c"># n by D matrix of test inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ys</span> <span class="o">=</span> <span class="bp">None</span>            <span class="c"># column vector of length nn of true test targets (optional)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">=</span> <span class="bp">None</span>            <span class="c"># column vector (of length ns) of predictive output means</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ys2</span> <span class="o">=</span> <span class="bp">None</span>           <span class="c"># column vector (of length ns) of predictive output variances</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fm</span> <span class="o">=</span> <span class="bp">None</span>            <span class="c"># column vector (of length ns) of predictive latent means</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fs2</span> <span class="o">=</span> <span class="bp">None</span>           <span class="c"># column vector (of length ns) of predictive latent variances</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lp</span> <span class="o">=</span> <span class="bp">None</span>            <span class="c"># column vector (of length ns) of log predictive probabilities</span>



    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
       <span class="n">strvalue</span> <span class="o">=</span> <span class="s">&#39;To get the properties of the model use:</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.nlZ          # negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.dnlZ.cov     # derivatives of cov func of negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.dnlZ.lik     # derivatives of lik func of negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.dnlZ.mean    # derivatives of mean func of negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.posterior    # posterior structure</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.covfunc.hyp  # hyperparameters of cov func</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.meanfunc.hyp # hyperparameters of mean func</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.likfunc.hyp  # hyperparameters of lik func</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.fm           # latent mean</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.fs2          # latent variance</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.ym           # predictive mean</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.ys2          # predictive variance</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.lp           # log predictive probability&#39;</span>
       <span class="k">return</span> <span class="n">strvalue</span>



    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
       <span class="n">strvalue</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span><span class="o">+</span><span class="s">&#39;: &#39;</span><span class="o">+</span>\
                  <span class="s">&#39;to get the properties of the model use:</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.nlZ          # negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.dnlZ.cov     # derivatives of cov func of negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.dnlZ.lik     # derivatives of lik func of negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.dnlZ.mean    # derivatives of mean func of negative log marginal likelihood</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.posterior    # posterior structure</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.covfunc.hyp  # hyperparameters of cov func</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.meanfunc.hyp # hyperparameters of mean func</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.likfunc.hyp  # hyperparameters of lik func</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.fm           # latent mean</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.fs2          # latent variance</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.ym           # predictive mean</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.ys2          # predictive variance</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">+</span>\
                  <span class="s">&#39;model.lp           # log predictive probability&#39;</span>
       <span class="k">return</span> <span class="n">strvalue</span>




    <span class="k">def</span> <span class="nf">setData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set training inputs and traning labels to model.</span>

<span class="sd">        :param x: training inputs in shape (n,D)</span>
<span class="sd">        :param y: training labels in shape (n,1)</span>

<span class="sd">        Note this method will transform x, y to correct shape</span>
<span class="sd">        if x, y is given in 1d array. </span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check wether the number of inputs and labels match</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&quot;number of inputs and labels does not match&quot;</span>

        <span class="c"># check the shape of inputs</span>
        <span class="c"># transform to the correct shape</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>    <span class="c"># adapt default prior mean wrt. training labels</span>



    <span class="k">def</span> <span class="nf">plotData_1d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axisvals</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Toy Method for ploting 1d data of the model.</span>

<span class="sd">        :param list axisvals: [min_x, max_x, min_y, max_y] setting the plot range</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">&#39;+&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">DATACOLOR</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">axisvals</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="n">axisvals</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;input x&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;target y&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>



    <span class="k">def</span> <span class="nf">plotData_2d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">p1</span><span class="p">,</span><span class="n">p2</span><span class="p">,</span><span class="n">axisvals</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Toy Method for ploting 2d data of the model. \n</span>
<span class="sd">        For plotting, we superimpose the data points with the posterior equi-probability contour </span>
<span class="sd">        lines for the probability of class two given complete information about the generating mechanism.</span>

<span class="sd">        :param x1: inputs for class +1</span>
<span class="sd">        :param x2: inputs for class -1</span>
<span class="sd">        :param t1: meshgrid array for the first axis</span>
<span class="sd">        :param t2: meshgrid array for the second axis</span>
<span class="sd">        :param p1,p2: contour lines contains p2/(p1+p2)</span>
<span class="sd">        :param list axisvals: [min_x, max_x, min_y, max_y] setting the plot range</span>

<span class="sd">        That is to say, the contour is ploted by plt.contour(t1, t2, p2/(p1+p2) )</span>
<span class="sd">        Note these parameters are (only) used for our hard-coded data for classification demo.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;b+&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;r+&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">pc</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">p2</span><span class="o">/</span><span class="p">(</span><span class="n">p1</span><span class="o">+</span><span class="n">p2</span><span class="p">),</span> <span class="p">(</span><span class="n">t1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">t1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">))</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pc</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">axisvals</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="n">axisvals</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>



    <span class="k">def</span> <span class="nf">setPrior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set prior mean and covariance other than the default setting of current model.</span>

<span class="sd">        :param mean: instance of mean class. (e.g. mean.Linear())</span>
<span class="sd">        :param kernel: instance of covariance class. (e.g. cov.RBF())</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check the type of inputs</span>
        <span class="c"># ensure they are the right class before setting prior</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mean</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">Mean</span><span class="p">),</span> <span class="s">&quot;mean function is not an instance of pyGPs.mean.Mean&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">cov</span><span class="o">.</span><span class="n">Kernel</span><span class="p">),</span> <span class="s">&quot;cov function is not an instance of pyGPs.cov.Kernel&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">kernel</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="ow">is</span> <span class="n">cov</span><span class="o">.</span><span class="n">Pre</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="o">=</span> <span class="bp">False</span>



<div class="viewcode-block" id="GP.setOptimizer"><a class="viewcode-back" href="../../../Opts.html#pyGPs.Core.gp.GP.setOptimizer">[docs]</a>    <span class="k">def</span> <span class="nf">setOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">min_threshold</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">meanRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">covRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likRange</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This method is used to sepecify optimization configuration. By default, gp uses a single run &quot;minimize&quot;.</span>

<span class="sd">        :param method: Optimization methods. Possible values are:\n</span>
<span class="sd">                       &quot;Minimize&quot;   -&gt; minimize by Carl Rasmussen (python implementation of &quot;minimize&quot; in GPML)\n</span>
<span class="sd">                       &quot;CG&quot;         -&gt; conjugent gradient\n</span>
<span class="sd">                       &quot;BFGS&quot;       -&gt; quasi-Newton method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS)\n</span>
<span class="sd">                       &quot;SCG&quot;        -&gt; scaled conjugent gradient (faster than CG)\n</span>
<span class="sd">        :param num_restarts: Set if you want to run mulitiple times of optimization with different initial guess.</span>
<span class="sd">                             It specifys the maximum number of runs/restarts/trials.</span>
<span class="sd">        :param min_threshold: Set if you want to run mulitiple times of optimization with different initial guess.</span>
<span class="sd">                              It specifys the threshold of objective function value. Stop optimization when this value is reached.</span>
<span class="sd">        :param meanRange: The range of initial guess for mean hyperparameters.</span>
<span class="sd">                          e.g. meanRange = [(-2,2), (-5,5), (0,1)].</span>
<span class="sd">                          Each tuple specifys the range (low, high) of this hyperparameter,</span>
<span class="sd">                          This is only the range of initial guess, during optimization process, optimal hyperparameters may go out of this range.</span>
<span class="sd">                          (-5,5) for each hyperparameter by default.</span>
<span class="sd">        :param covRange: The range of initial guess for kernel hyperparameters. Usage see meanRange</span>
<span class="sd">        :param likRange: The range of initial guess for likelihood hyperparameters. Usage see meanRange</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">pass</span>


</div>
    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">numIterations</span><span class="o">=</span><span class="mi">40</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Train optimal hyperparameters based on training data,</span>
<span class="sd">        adjust new hyperparameters to all mean/cov/lik functions.</span>

<span class="sd">        :param x: training inputs in shape (n,D)</span>
<span class="sd">        :param y: training labels in shape (n,1)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check wether the number of inputs and labels match</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> 
            <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&quot;number of inputs and labels does not match&quot;</span>

        <span class="c"># check the shape of inputs</span>
        <span class="c"># transform to the correct shape</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">y</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>    <span class="c"># adapt default prior mean wrt. training labels</span>

        <span class="c"># optimize</span>
        <span class="n">optimalHyp</span><span class="p">,</span> <span class="n">optimalNlZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">findMin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">numIters</span> <span class="o">=</span> <span class="n">numIterations</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nlZ</span> <span class="o">=</span> <span class="n">optimalNlZ</span>

        <span class="c"># apply optimal hyp to all mean/cov/lik functions here</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">_apply_in_objects</span><span class="p">(</span><span class="n">optimalHyp</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">getPosterior</span><span class="p">()</span>



    <span class="k">def</span> <span class="nf">getPosterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">der</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Fit the training data. Update negative log marginal likelihood(nlZ),</span>
<span class="sd">        partial derivatives of nlZ w.r.t. each hyperparameter(dnlZ),</span>
<span class="sd">        and struct representation of the (approximate) posterior(post),</span>
<span class="sd">        which consists of post.alpha, post.L, post.sW.</span>

<span class="sd">        nlZ, dnlZ, post = getPosterior(x, y, der=True)\n</span>
<span class="sd">        nlZ, post       = getPosterior(x, y, der=False )</span>

<span class="sd">        :param x: training inputs in shape (n,D)</span>
<span class="sd">        :param y: training labels in shape (n,1)</span>
<span class="sd">        :param boolean der: flag for whether to compute derivatives</span>

<span class="sd">        :return: negative log marginal likelihood (nlZ), derivatives of nlZ (dnlZ), posterior structure(post)</span>

<span class="sd">        You can print post to see descriptions of posterior.</span>
<span class="sd">        or see pyGPs.Core.inf for details.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c"># check wether the number of inputs and labels match</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> 
            <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&quot;number of inputs and labels does not match&quot;</span>

        <span class="c"># check the shape of inputs</span>
        <span class="c"># transform to the correct shape</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">y</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>    <span class="c"># adapt default prior mean wrt. training labels</span>
            
        <span class="c"># call inference method</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span><span class="p">,</span> <span class="n">lik</span><span class="o">.</span><span class="n">Erf</span><span class="p">):</span> <span class="c">#or is instance(self.likfunc, lik.Logistic):</span>
            <span class="n">uy</span>  <span class="o">=</span> <span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="p">(</span> <span class="n">uy</span> <span class="o">!=</span> <span class="mi">1</span> <span class="p">)</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span> <span class="n">uy</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;You attempt classification using labels different from {+1,-1}&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">der</span><span class="p">:</span>
            <span class="n">post</span><span class="p">,</span> <span class="n">nlZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nlZ</span> <span class="o">=</span> <span class="n">nlZ</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">nlZ</span><span class="p">,</span> <span class="n">post</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">post</span><span class="p">,</span> <span class="n">nlZ</span><span class="p">,</span> <span class="n">dnlZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nlZ</span>       <span class="o">=</span> <span class="n">nlZ</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dnlZ</span>      <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">dnlZ</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">nlZ</span><span class="p">,</span> <span class="n">dnlZ</span><span class="p">,</span> <span class="n">post</span>



    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Prediction of test points (given by xs) based on training data of the current model.</span>
<span class="sd">        This method will output the following value:\n</span>
<span class="sd">        predictive output means(ym),\n</span>
<span class="sd">        predictive output variances(ys2),\n</span>
<span class="sd">        predictive latent means(fm),\n</span>
<span class="sd">        predictive latent variances(fs2),\n</span>
<span class="sd">        log predictive probabilities(lp).\n</span>
<span class="sd">        Theses values can also be achieved from model&#39;s property. (e.g. model.ym)</span>

<span class="sd">        :param xs: test input in shape of nn by D</span>
<span class="sd">        :param ys: test target(optional) in shape of nn by 1 if given</span>

<span class="sd">        :return: ym, ys2, fm, fs2, lp</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check the shape of inputs</span>
        <span class="c"># transform to correct shape if neccessary</span>
        <span class="k">if</span> <span class="n">xs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ys</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ys</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span>

        <span class="n">meanfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span>
        <span class="n">covfunc</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span>
        <span class="n">likfunc</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span>
        <span class="n">inffunc</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">getPosterior</span><span class="p">()</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">L</span>     <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="o">.</span><span class="n">L</span>
        <span class="n">sW</span>    <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="o">.</span><span class="n">sW</span>

        <span class="n">nz</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alpha</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>         <span class="c"># non-sparse representation</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">==</span> <span class="p">[]:</span>                         <span class="c"># in case L is not provided, we compute it</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">covfunc</span><span class="o">.</span><span class="n">getCovMatrix</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">nz</span><span class="p">,:],</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;train&#39;</span><span class="p">)</span>
            <span class="c">#L = np.linalg.cholesky( (np.eye(nz) + np.dot(sW,sW.T)*K).T )</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">jitchol</span><span class="p">(</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nz</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sW</span><span class="p">,</span><span class="n">sW</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">*</span><span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="p">)</span>
        <span class="n">Ltril</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="c"># is L an upper triangular matrix?</span>
        <span class="n">ns</span>        <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                  <span class="c"># number of data points</span>
        <span class="n">nperbatch</span> <span class="o">=</span> <span class="mi">1000</span>                         <span class="c"># number of data points per mini batch</span>
        <span class="n">nact</span>      <span class="o">=</span> <span class="mi">0</span>                            <span class="c"># number of already processed test data points</span>
        <span class="n">ymu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">ys2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">fmu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">fs2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">lp</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">while</span> <span class="n">nact</span><span class="o">&lt;=</span><span class="n">ns</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>                              <span class="c"># process minibatches of test cases to save memory</span>
            <span class="nb">id</span>  <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">nact</span><span class="p">,</span><span class="nb">min</span><span class="p">(</span><span class="n">nact</span><span class="o">+</span><span class="n">nperbatch</span><span class="p">,</span><span class="n">ns</span><span class="p">))</span>   <span class="c"># data points to process</span>
            <span class="n">kss</span> <span class="o">=</span> <span class="n">covfunc</span><span class="o">.</span><span class="n">getCovMatrix</span><span class="p">(</span><span class="n">z</span><span class="o">=</span><span class="n">xs</span><span class="p">[</span><span class="nb">id</span><span class="p">,:],</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;self_test&#39;</span><span class="p">)</span>    <span class="c"># self-variances</span>
            <span class="n">Ks</span>  <span class="o">=</span> <span class="n">covfunc</span><span class="o">.</span><span class="n">getCovMatrix</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">nz</span><span class="p">,:],</span> <span class="n">z</span><span class="o">=</span><span class="n">xs</span><span class="p">[</span><span class="nb">id</span><span class="p">,:],</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;cross&#39;</span><span class="p">)</span>   <span class="c"># cross-covariances</span>
            <span class="n">ms</span>  <span class="o">=</span> <span class="n">meanfunc</span><span class="o">.</span><span class="n">getMean</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="nb">id</span><span class="p">,:])</span>
            <span class="n">N</span>   <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>                     <span class="c"># number of alphas (usually 1; more in case of sampling)</span>
            <span class="n">Fmu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">ms</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ks</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">alpha</span><span class="p">[</span><span class="n">nz</span><span class="p">])</span>          <span class="c"># conditional mean fs|f</span>
            <span class="n">fmu</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Fmu</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>       <span class="c"># predictive means</span>
            <span class="k">if</span> <span class="n">Ltril</span><span class="p">:</span> <span class="c"># L is triangular =&gt; use Cholesky parameters (alpha,sW,L)</span>
                <span class="n">V</span>       <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">sW</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">)))</span><span class="o">*</span><span class="n">Ks</span><span class="p">)</span>
                <span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">kss</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">V</span><span class="o">*</span><span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>             <span class="c"># predictive variances</span>
            <span class="k">else</span><span class="p">:</span>     <span class="c"># L is not triangular =&gt; use alternative parametrization</span>
                <span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">kss</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">Ks</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">Ks</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span> <span class="c"># predictive variances</span>
            <span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span>            <span class="c"># remove numerical noise i.e. negative variances</span>
            <span class="n">Fs2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">],(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">))</span>               <span class="c"># we have multiple values in case of sampling</span>
            <span class="k">if</span> <span class="n">ys</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">Lp</span><span class="p">,</span> <span class="n">Ymu</span><span class="p">,</span> <span class="n">Ys2</span> <span class="o">=</span> <span class="n">likfunc</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">Fmu</span><span class="p">[:],</span><span class="n">Fs2</span><span class="p">[:],</span><span class="bp">None</span><span class="p">,</span><span class="bp">None</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Lp</span><span class="p">,</span> <span class="n">Ymu</span><span class="p">,</span> <span class="n">Ys2</span> <span class="o">=</span> <span class="n">likfunc</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="nb">id</span><span class="p">],(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">)),</span> <span class="n">Fmu</span><span class="p">[:],</span> <span class="n">Fs2</span><span class="p">[:],</span><span class="bp">None</span><span class="p">,</span><span class="bp">None</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">lp</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Lp</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">Lp</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span> <span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>   <span class="c"># log probability; sample averaging</span>
            <span class="n">ymu</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Ymu</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">Ymu</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span> <span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>  <span class="c"># predictive mean ys|y and ...</span>
            <span class="n">ys2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Ys2</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">Ys2</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span> <span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span> <span class="c"># .. variance</span>
            <span class="n">nact</span> <span class="o">=</span> <span class="nb">id</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>                  <span class="c"># set counter to index of next data point</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">=</span> <span class="n">ymu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ys2</span> <span class="o">=</span> <span class="n">ys2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lp</span> <span class="o">=</span> <span class="n">lp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fm</span> <span class="o">=</span> <span class="n">fmu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fs2</span> <span class="o">=</span> <span class="n">fs2</span>
        <span class="k">if</span> <span class="n">ys</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ymu</span><span class="p">,</span> <span class="n">ys2</span><span class="p">,</span> <span class="n">fmu</span><span class="p">,</span> <span class="n">fs2</span><span class="p">,</span> <span class="bp">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ymu</span><span class="p">,</span> <span class="n">ys2</span><span class="p">,</span> <span class="n">fmu</span><span class="p">,</span> <span class="n">fs2</span><span class="p">,</span> <span class="n">lp</span>



    <span class="k">def</span> <span class="nf">predict_with_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Prediction of test points (given by xs) based on training data </span>
<span class="sd">        of the current model with posterior already provided.</span>
<span class="sd">        (i.e. you already have the posterior and thus don&#39;t need the fitting phase.)</span>
<span class="sd">        This method will output the following value:\n</span>
<span class="sd">        predictive output means(ym),\n</span>
<span class="sd">        predictive output variances(ys2),\n</span>
<span class="sd">        predictive latent means(fm),\n</span>
<span class="sd">        predictive latent variances(fs2),\n</span>
<span class="sd">        log predictive probabilities(lp).\n</span>
<span class="sd">        Theses values can also be achieved from model&#39;s property. (e.g. model.ym)</span>

<span class="sd">        :param post: struct representation of posterior</span>
<span class="sd">        :param xs: test input</span>
<span class="sd">        :param ys: test target(optional)</span>

<span class="sd">        :return: ym, ys2, fm, fs2, lp</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check the shape of inputs</span>
        <span class="c"># transform to correct shape if neccessary</span>
        <span class="k">if</span> <span class="n">xs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ys</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ys</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span>

        <span class="n">meanfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span>
        <span class="n">covfunc</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span>
        <span class="n">likfunc</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span>
        <span class="n">inffunc</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">post</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">post</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">L</span>     <span class="o">=</span> <span class="n">post</span><span class="o">.</span><span class="n">L</span>
        <span class="n">sW</span>    <span class="o">=</span> <span class="n">post</span><span class="o">.</span><span class="n">sW</span>

        <span class="n">nz</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alpha</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>         <span class="c"># non-sparse representation</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">==</span> <span class="p">[]:</span>                         <span class="c"># in case L is not provided, we compute it</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">covfunc</span><span class="o">.</span><span class="n">getCovMatrix</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">nz</span><span class="p">,:],</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;train&#39;</span><span class="p">)</span>
            <span class="c">#L = np.linalg.cholesky( (np.eye(nz) + np.dot(sW,sW.T)*K).T )</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">jitchol</span><span class="p">(</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nz</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sW</span><span class="p">,</span><span class="n">sW</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">*</span><span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="p">)</span>
        <span class="n">Ltril</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="c"># is L an upper triangular matrix?</span>
        <span class="n">ns</span>        <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                  <span class="c"># number of data points</span>
        <span class="n">nperbatch</span> <span class="o">=</span> <span class="mi">1000</span>                         <span class="c"># number of data points per mini batch</span>
        <span class="n">nact</span>      <span class="o">=</span> <span class="mi">0</span>                            <span class="c"># number of already processed test data points</span>
        <span class="n">ymu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">ys2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">fmu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">fs2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">lp</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">while</span> <span class="n">nact</span><span class="o">&lt;=</span><span class="n">ns</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>                              <span class="c"># process minibatches of test cases to save memory</span>
            <span class="nb">id</span>  <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">nact</span><span class="p">,</span><span class="nb">min</span><span class="p">(</span><span class="n">nact</span><span class="o">+</span><span class="n">nperbatch</span><span class="p">,</span><span class="n">ns</span><span class="p">))</span>   <span class="c"># data points to process</span>
            <span class="n">kss</span> <span class="o">=</span> <span class="n">covfunc</span><span class="o">.</span><span class="n">getCovMatrix</span><span class="p">(</span><span class="n">z</span><span class="o">=</span><span class="n">xs</span><span class="p">[</span><span class="nb">id</span><span class="p">,:],</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;self_test&#39;</span><span class="p">)</span>    <span class="c"># self-variances</span>
            <span class="n">Ks</span>  <span class="o">=</span> <span class="n">covfunc</span><span class="o">.</span><span class="n">getCovMatrix</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">nz</span><span class="p">,:],</span> <span class="n">z</span><span class="o">=</span><span class="n">xs</span><span class="p">[</span><span class="nb">id</span><span class="p">,:],</span> <span class="n">mode</span><span class="o">=</span><span class="s">&#39;cross&#39;</span><span class="p">)</span>   <span class="c"># cross-covariances</span>
            <span class="n">ms</span>  <span class="o">=</span> <span class="n">meanfunc</span><span class="o">.</span><span class="n">getMean</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="nb">id</span><span class="p">,:])</span>
            <span class="n">N</span>   <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>                     <span class="c"># number of alphas (usually 1; more in case of sampling)</span>
            <span class="n">Fmu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">ms</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ks</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">alpha</span><span class="p">[</span><span class="n">nz</span><span class="p">])</span>          <span class="c"># conditional mean fs|f</span>
            <span class="n">fmu</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Fmu</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>       <span class="c"># predictive means</span>
            <span class="k">if</span> <span class="n">Ltril</span><span class="p">:</span> <span class="c"># L is triangular =&gt; use Cholesky parameters (alpha,sW,L)</span>
                <span class="n">V</span>       <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">sW</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">)))</span><span class="o">*</span><span class="n">Ks</span><span class="p">)</span>
                <span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">kss</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">V</span><span class="o">*</span><span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>             <span class="c"># predictive variances</span>
            <span class="k">else</span><span class="p">:</span>     <span class="c"># L is not triangular =&gt; use alternative parametrization</span>
                <span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">kss</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">Ks</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">Ks</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span> <span class="c"># predictive variances</span>
            <span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span>            <span class="c"># remove numerical noise i.e. negative variances</span>
            <span class="n">Fs2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">fs2</span><span class="p">[</span><span class="nb">id</span><span class="p">],(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">))</span>               <span class="c"># we have multiple values in case of sampling</span>
            <span class="k">if</span> <span class="n">ys</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="p">[</span><span class="n">Lp</span><span class="p">,</span> <span class="n">Ymu</span><span class="p">,</span> <span class="n">Ys2</span><span class="p">]</span> <span class="o">=</span> <span class="n">likfunc</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">Fmu</span><span class="p">[:],</span><span class="n">Fs2</span><span class="p">[:],</span><span class="bp">None</span><span class="p">,</span><span class="bp">None</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="p">[</span><span class="n">Lp</span><span class="p">,</span> <span class="n">Ymu</span><span class="p">,</span> <span class="n">Ys2</span><span class="p">]</span> <span class="o">=</span> <span class="n">likfunc</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="nb">id</span><span class="p">],(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">)),</span> <span class="n">Fmu</span><span class="p">[:],</span> <span class="n">Fs2</span><span class="p">[:],</span><span class="bp">None</span><span class="p">,</span><span class="bp">None</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">lp</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Lp</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">Lp</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span> <span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>   <span class="c"># log probability; sample averaging</span>
            <span class="n">ymu</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Ymu</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">Ymu</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span> <span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>  <span class="c"># predictive mean ys|y and ...</span>
            <span class="n">ys2</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Ys2</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">Ys2</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">N</span> <span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">id</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span> <span class="c"># .. variance</span>
            <span class="n">nact</span> <span class="o">=</span> <span class="nb">id</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>                  <span class="c"># set counter to index of next data point</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ym</span>  <span class="o">=</span> <span class="n">ymu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ys2</span> <span class="o">=</span> <span class="n">ys2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lp</span>  <span class="o">=</span> <span class="n">lp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fm</span>  <span class="o">=</span> <span class="n">fmu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fs2</span> <span class="o">=</span> <span class="n">fs2</span>
        <span class="k">if</span> <span class="n">ys</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ymu</span><span class="p">,</span> <span class="n">ys2</span><span class="p">,</span> <span class="n">fmu</span><span class="p">,</span> <span class="n">fs2</span><span class="p">,</span> <span class="bp">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ymu</span><span class="p">,</span> <span class="n">ys2</span><span class="p">,</span> <span class="n">fmu</span><span class="p">,</span> <span class="n">fs2</span><span class="p">,</span> <span class="n">lp</span>





<span class="k">class</span> <span class="nc">GPR</span><span class="p">(</span><span class="n">GP</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Model for Gaussian Process Regression</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GPR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Zero</span><span class="p">()</span>                        <span class="c"># default prior mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">cov</span><span class="o">.</span><span class="n">RBF</span><span class="p">()</span>                           <span class="c"># default prior covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Gauss</span><span class="p">()</span>                         <span class="c"># likihood with default noise variance 0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">Exact</span><span class="p">()</span>                         <span class="c"># inference method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>                <span class="c"># default optimizer</span>



    <span class="k">def</span> <span class="nf">setNoise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">log_sigma</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set noise other than default noise value</span>

<span class="sd">        :param log_sigma: logorithm of the noise sigma</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Gauss</span><span class="p">(</span><span class="n">log_sigma</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">setOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">min_threshold</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">meanRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">covRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likRange</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Overriding. Usage see base class pyGPs.gp.GP.setOptimizer</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">conf</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">num_restarts</span><span class="o">!=</span><span class="bp">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">min_threshold</span><span class="o">!=</span><span class="bp">None</span><span class="p">):</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">Optimization</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">random_init_conf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span><span class="p">)</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">num_restarts</span> <span class="o">=</span> <span class="n">num_restarts</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">min_threshold</span> <span class="o">=</span> <span class="n">min_threshold</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">meanRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">=</span> <span class="n">meanRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">covRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">covRange</span> <span class="o">=</span> <span class="n">covRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">likRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">likRange</span> <span class="o">=</span> <span class="n">likRange</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;Minimize&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;SCG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">SCG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;CG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">CG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;BFGS&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">BFGS</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;LBFGSB&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">LBFGSB</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;COBYLA&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">COBYLA</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;RTMinimize&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">RTMinimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">Error</span><span class="p">(</span><span class="s">&#39;Optimization method is not set correctly in setOptimizer&#39;</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">axisvals</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Plot 1d GP regression result.</span>

<span class="sd">        :param list axisvals: [min_x, max_x, min_y, max_y] setting the plot range</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs</span>    <span class="c"># test point</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
        <span class="n">ym</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span>    <span class="c"># predictive test mean</span>
        <span class="n">ys2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ys2</span>  <span class="c"># predictive test variance</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">xss</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xs</span><span class="p">,(</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="n">ymm</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ym</span><span class="p">,(</span><span class="n">ym</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="n">ys22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ys2</span><span class="p">,(</span><span class="n">ys2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">DATACOLOR</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">&#39;+&#39;</span><span class="p">,</span><span class="n">ms</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ym</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">MEANCOLOR</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">&#39;-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">3.</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">xss</span><span class="p">,</span><span class="n">ymm</span> <span class="o">+</span> <span class="mf">2.</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">ys22</span><span class="p">),</span> <span class="n">ymm</span> <span class="o">-</span> <span class="mf">2.</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">ys22</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">SHADEDCOLOR</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">axisvals</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="n">axisvals</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;input x&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;target y&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">useInference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">newInf</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another inference techinique other than default exact inference.</span>

<span class="sd">        :param str newInf: &#39;Laplace&#39; or &#39;EP&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newInf</span> <span class="o">==</span> <span class="s">&quot;Laplace&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">Laplace</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">newInf</span> <span class="o">==</span> <span class="s">&quot;EP&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">EP</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible inf values are &quot;Laplace&quot;, &quot;EP&quot;.&#39;</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">useLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">newLik</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another likelihood function other than default Gaussian likelihood.</span>

<span class="sd">        :param str newLik: &#39;Laplace&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newLik</span> <span class="o">==</span> <span class="s">&quot;Laplace&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Laplace</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">EP</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible lik values are &quot;Laplace&quot;.&#39;</span><span class="p">)</span>





<span class="k">class</span> <span class="nc">GPC</span><span class="p">(</span><span class="n">GP</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Model for Gaussian Process Classification.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GPC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Zero</span><span class="p">()</span>                        <span class="c"># default prior mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">cov</span><span class="o">.</span><span class="n">RBF</span><span class="p">()</span>                           <span class="c"># default prior covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Erf</span><span class="p">()</span>                           <span class="c"># erf likihood</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">EP</span><span class="p">()</span>                            <span class="c"># default inference method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>                <span class="c"># default optimizer</span>



    <span class="k">def</span> <span class="nf">setOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">min_threshold</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">meanRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">covRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likRange</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Overriding. Usage see base class pyGPs.gp.GP.setOptimizer</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">conf</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">num_restarts</span><span class="o">!=</span><span class="bp">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">min_threshold</span><span class="o">!=</span><span class="bp">None</span><span class="p">):</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">Optimization</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">random_init_conf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span><span class="p">)</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">num_restarts</span> <span class="o">=</span> <span class="n">num_restarts</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">min_threshold</span> <span class="o">=</span> <span class="n">min_threshold</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">meanRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">=</span> <span class="n">meanRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">covRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">covRange</span> <span class="o">=</span> <span class="n">covRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">likRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">likRange</span> <span class="o">=</span> <span class="n">likRange</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;Minimize&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;SCG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">SCG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;CG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">CG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;BFGS&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">BFGS</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">axisvals</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Plot 2d GP Classification result.</span>

<span class="sd">        For plotting, we superimpose the data points with the posterior equi-probability contour </span>
<span class="sd">        lines for the probability of class two given complete information about the generating mechanism.</span>

<span class="sd">        :param x1: inputs for class +1</span>
<span class="sd">        :param x2: inputs for class -1</span>
<span class="sd">        :param t1: meshgrid array for the first axis</span>
<span class="sd">        :param t2: meshgrid array for the second axis</span>
<span class="sd">        :param list axisvals: [min_x, max_x, min_y, max_y] setting the plot range</span>

<span class="sd">        Note these parameters are (only) used for our hard-coded data for classification demo.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;b+&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;r+&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">pc</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lp</span><span class="p">),</span> <span class="p">(</span><span class="n">t1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">t1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">))</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pc</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">axisvals</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="n">axisvals</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>



    <span class="k">def</span> <span class="nf">useInference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">newInf</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another inference techinique other than default EP inference.</span>

<span class="sd">        :param str newInf: &#39;Laplace&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newInf</span> <span class="o">==</span> <span class="s">&quot;Laplace&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">Laplace</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible inf values are &quot;Laplace&quot;.&#39;</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">useLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">newLik</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another likelihood function other than default error function.</span>
<span class="sd">        (Not used in this version)</span>

<span class="sd">        :param str newLik: &#39;Logistic&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newLik</span> <span class="o">==</span> <span class="s">&quot;Logistic&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Logistic likelihood is currently not implemented.&quot;</span><span class="p">)</span>
            <span class="c">#self.likfunc = lik.Logistic()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible lik values are &quot;Logistic&quot;.&#39;</span><span class="p">)</span>





<span class="k">class</span> <span class="nc">GPMC</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This is a one vs. one classification wrapper for GP Classification</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_class</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Zero</span><span class="p">()</span>                <span class="c"># default prior mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">cov</span><span class="o">.</span><span class="n">RBF</span><span class="p">()</span>                   <span class="c"># default prior covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_class</span> <span class="o">=</span> <span class="n">n_class</span>                     <span class="c"># number of different classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_all</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_all</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newInf</span> <span class="o">=</span> <span class="bp">None</span>                         <span class="c"># new inference? -&gt; call useInference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newLik</span> <span class="o">=</span> <span class="bp">None</span>                         <span class="c"># new likelihood? -&gt; call useLikelihood</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newPrior</span> <span class="o">=</span> <span class="bp">False</span>



    <span class="k">def</span> <span class="nf">setPrior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set prior mean and covariance other than the default setting of current model.</span>

<span class="sd">        :param mean: instance of mean class. (e.g. mean.Linear())</span>
<span class="sd">        :param kernel: instance of covariance class. (e.g. cov.RBF())</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check the type of inputs</span>
        <span class="c"># ensure they are the right class before setting prior</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mean</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">Mean</span><span class="p">),</span> <span class="s">&quot;mean function is not an instance of pyGPs.mean.Mean&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">cov</span><span class="o">.</span><span class="n">Kernel</span><span class="p">),</span> <span class="s">&quot;cov function is not an instance of pyGPs.cov.Kernel&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">kernel</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="ow">is</span> <span class="n">cov</span><span class="o">.</span><span class="n">Pre</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newPrior</span> <span class="o">=</span> <span class="bp">True</span>



    <span class="k">def</span> <span class="nf">useInference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">newInf</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another inference techinique other than default EP inference.</span>

<span class="sd">        :param str newInf: &#39;Laplace&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newInf</span> <span class="o">==</span> <span class="s">&quot;Laplace&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">Laplace</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible inf values are &quot;Laplace&quot;.&#39;</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">useLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">newLik</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another likelihood function other than default error function.</span>
<span class="sd">        (Not used in this version)</span>

<span class="sd">        :param str newLik: &#39;Logistic&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newLik</span> <span class="o">==</span> <span class="s">&quot;Logistic&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="s">&quot;Logistic likelihood is currently not implemented.&quot;</span>
            <span class="c">#self.likfunc = lik.Logistic()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible lik values are &quot;Logistic&quot;.&#39;</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">setData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set training inputs and traning labels to model.</span>

<span class="sd">        :param x: training inputs in shape (n,D)</span>
<span class="sd">        :param y: training labels in shape (n,1)</span>

<span class="sd">        Note this method will transform x, y to correct shape</span>
<span class="sd">        if x, y is given in 1d array. </span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check wether the number of inputs and labels match</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&quot;number of inputs and labels does not match&quot;</span>

        <span class="c"># check the shape of inputs</span>
        <span class="c"># transform to the correct shape</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">x_all</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_all</span> <span class="o">=</span> <span class="n">y</span>



    <span class="k">def</span> <span class="nf">fitAndPredict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Fit the model with given training data and predict for test points (given by xs).</span>
<span class="sd">        predictive_vote is a matrix where row i is each test point i,</span>
<span class="sd">        and column j is the probability for being class j</span>

<span class="sd">        :param xs: test inputs in shape of nn by D</span>
<span class="sd">        :return: predictive_vote</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check the shape of inputs</span>
        <span class="k">if</span> <span class="n">xs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">predictive_vote</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">):</span>         <span class="c"># classifier for class i...</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">):</span> <span class="c"># ...and class j</span>
                <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">createBinaryClass</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">GPC</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">newPrior</span><span class="p">:</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">setPrior</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">newInf</span><span class="p">:</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">useInference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">newInf</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">newLik</span><span class="p">:</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">useLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">newLik</span><span class="p">)</span>
                <span class="n">model</span><span class="o">.</span><span class="n">getPosterior</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>               <span class="c"># fitting</span>
                <span class="n">ym</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">ym</span> <span class="o">+=</span> <span class="mi">1</span>     <span class="c"># now scale into 0 to 2,  ym=0 is class j, ym=2 is class i</span>
                <span class="n">vote_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">))</span>
                <span class="n">vote_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">))</span>
                <span class="n">vote_i</span><span class="p">[:,</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">ym</span>
                <span class="n">vote_j</span><span class="p">[:,</span><span class="n">j</span><span class="p">:</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="o">-</span><span class="n">ym</span>
                <span class="n">predictive_vote</span> <span class="o">+=</span> <span class="n">vote_i</span>
                <span class="n">predictive_vote</span> <span class="o">+=</span> <span class="n">vote_j</span>
        <span class="n">predictive_vote</span> <span class="o">/=</span>  <span class="n">predictive_vote</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">predictive_vote</span>



    <span class="k">def</span> <span class="nf">optimizeAndPredict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Optimize the model with given training data and predict for test points (given by xs).</span>
<span class="sd">        predictive_vote is a matrix where row i is each test point i,</span>
<span class="sd">        and column j is the probability for being class j</span>

<span class="sd">        :param xs: test inputs in shape of nn by D</span>
<span class="sd">        :return: predictive_vote</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check the shape of inputs</span>
        <span class="k">if</span> <span class="n">xs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">predictive_vote</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">):</span>         <span class="c"># classifier for class i...</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">):</span> <span class="c"># ...and class j</span>
                <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">createBinaryClass</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">GPC</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">newPrior</span><span class="p">:</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">setPrior</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">newInf</span><span class="p">:</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">useInference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">newInf</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">newLik</span><span class="p">:</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">useLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">newLik</span><span class="p">)</span>
                <span class="n">model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>               <span class="c"># training</span>
                <span class="n">ym</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">ym</span> <span class="o">+=</span> <span class="mi">1</span>     <span class="c"># now scale into 0 to 2,  ym=0 is class j, ym=2 is class i</span>
                <span class="n">vote_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">))</span>
                <span class="n">vote_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">))</span>
                <span class="n">vote_i</span><span class="p">[:,</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">ym</span>
                <span class="n">vote_j</span><span class="p">[:,</span><span class="n">j</span><span class="p">:</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="o">-</span><span class="n">ym</span>
                <span class="n">predictive_vote</span> <span class="o">+=</span> <span class="n">vote_i</span>
                <span class="n">predictive_vote</span> <span class="o">+=</span> <span class="n">vote_j</span>
        <span class="n">predictive_vote</span> <span class="o">/=</span>  <span class="n">predictive_vote</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">predictive_vote</span>



    <span class="k">def</span> <span class="nf">createBinaryClass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; </span>
<span class="sd">        Create dataset x(data) and y(label) which only contains class i and j.</span>
<span class="sd">        Relabel class i to +1 and class j to -1</span>

<span class="sd">        :param int i: the i_th class</span>
<span class="sd">        :param int j: the j_th class</span>
<span class="sd">        :return: x(data) and y(label) which only contains class i and j</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">class_i</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">class_j</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_all</span><span class="p">)):</span>       <span class="c"># check all classes</span>
            <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_all</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
                <span class="n">class_i</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">target</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">class_j</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">n1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_i</span><span class="p">)</span>
        <span class="n">n2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_j</span><span class="p">)</span>
        <span class="n">class_i</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">class_j</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_all</span><span class="p">[</span><span class="n">class_i</span><span class="p">,:]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">n1</span><span class="p">)),</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">n2</span><span class="p">))),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span>





<span class="k">class</span> <span class="nc">GP_FITC</span><span class="p">(</span><span class="n">GP</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Model for FITC GP base class</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GP_FITC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="bp">None</span>                  <span class="c"># inducing points</span>



    <span class="k">def</span> <span class="nf">setData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">value_per_axis</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set training inputs and traning labels to model and derive deault inducing_points..</span>

<span class="sd">        :param x: training inputs in shape (n,D)</span>
<span class="sd">        :param y: training labels in shape (n,1)</span>
<span class="sd">        :param int value_per_axis: number of value in each dimension</span>
<span class="sd">                                   when using a uni-distant default inducing points</span>

<span class="sd">        Note this method will transform x, y to correct shape</span>
<span class="sd">        if x, y is given in 1d array. </span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># check wether the number of inputs and labels match</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&quot;number of inputs and labels does not match&quot;</span>

        <span class="c"># check dimension of inputs</span>
        <span class="c"># transform to correct shape if neccessary</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>    <span class="c"># adapt default prior mean wrt. training labels</span>

        <span class="c"># get range of x in each dimension</span>
        <span class="c"># 5 uniformally selected value for each dimension</span>
        <span class="n">gridAxis</span><span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">column</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="n">d</span><span class="p">]</span>
            <span class="n">mini</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
            <span class="n">maxi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
            <span class="n">axis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mini</span><span class="p">,</span><span class="n">maxi</span><span class="p">,</span><span class="n">value_per_axis</span><span class="p">)</span>
            <span class="n">gridAxis</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="c"># default inducing points-&gt; a grid</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">gridAxis</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="o">.</span><span class="n">fitc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">setPrior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">inducing_points</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set prior mean and covariance other than the default setting of current model,</span>
<span class="sd">        as well as the inducing points</span>

<span class="sd">        :param mean: instance of mean class. (e.g. mean.Linear())</span>
<span class="sd">        :param kernel: instance of covariance class. (e.g. cov.RBF())</span>
<span class="sd">        :inducing_points: matrix of inducing points in shape of (nu,D)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">inducing_points</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">fitc</span><span class="p">(</span><span class="n">inducing_points</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="n">inducing_points</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">fitc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">error</span><span class="p">(</span><span class="s">&quot;To use default inducing points, please call setData() first!&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span> <span class="ow">is</span> <span class="n">cov</span><span class="o">.</span><span class="n">Pre</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mean</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">usingDefaultMean</span> <span class="o">=</span> <span class="bp">False</span>





<span class="k">class</span> <span class="nc">GPR_FITC</span><span class="p">(</span><span class="n">GP_FITC</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Model for Gaussian Process Regression FITC</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GPR_FITC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Zero</span><span class="p">()</span>                        <span class="c"># default prior mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">cov</span><span class="o">.</span><span class="n">RBF</span><span class="p">()</span>                           <span class="c"># default prior covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Gauss</span><span class="p">()</span>                         <span class="c"># likihood with default noise variance 0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">FITC_Exact</span><span class="p">()</span>                    <span class="c"># inference method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>                <span class="c"># default optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="bp">None</span>                                      <span class="c"># no default inducing points</span>



    <span class="k">def</span> <span class="nf">setNoise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">log_sigma</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set noise other than default noise value</span>

<span class="sd">        :param log_sigma: logorithm of the noise sigma</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Gauss</span><span class="p">(</span><span class="n">log_sigma</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">setOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">min_threshold</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">meanRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">covRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likRange</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Overriding. Usage see base class pyGPs.gp.GP.setOptimizer</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">conf</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">num_restarts</span><span class="o">!=</span><span class="bp">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">min_threshold</span><span class="o">!=</span><span class="bp">None</span><span class="p">):</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">Optimization</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">random_init_conf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span><span class="p">)</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">num_restarts</span> <span class="o">=</span> <span class="n">num_restarts</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">min_threshold</span> <span class="o">=</span> <span class="n">min_threshold</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">meanRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">=</span> <span class="n">meanRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">covRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">covRange</span> <span class="o">=</span> <span class="n">covRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">likRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">likRange</span> <span class="o">=</span> <span class="n">likRange</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;Minimize&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;SCG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">SCG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;CG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">CG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;BFGS&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">BFGS</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">axisvals</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Plot 1d GP FITC Regression result.</span>

<span class="sd">        :param list axisvals: [min_x, max_x, min_y, max_y] setting the plot range</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">xss</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs</span><span class="p">,(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="n">ymm</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="n">ys22</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ys2</span><span class="p">,(</span><span class="bp">self</span><span class="o">.</span><span class="n">ys2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">DATACOLOR</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">&#39;+&#39;</span><span class="p">,</span><span class="n">ms</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">MEANCOLOR</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">&#39;-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">3.</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">xss</span><span class="p">,</span><span class="n">ymm</span> <span class="o">+</span> <span class="mf">2.</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">ys22</span><span class="p">),</span> <span class="n">ymm</span> <span class="o">-</span> <span class="mf">2.</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">ys22</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">SHADEDCOLOR</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">axisvals</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="n">axisvals</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;input x&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;output y&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">),</span> <span class="n">ls</span><span class="o">=</span><span class="s">&#39;None&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;k&#39;</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s">&#39;x&#39;</span><span class="p">,</span><span class="n">markersize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span><span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>



    <span class="k">def</span> <span class="nf">useInference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">newInf</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another inference techinique other than default exact inference.</span>

<span class="sd">        :param str newInf: &#39;Laplace&#39; or &#39;EP&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newInf</span> <span class="o">==</span> <span class="s">&quot;Laplace&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">FITC_Laplace</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">newInf</span> <span class="o">==</span> <span class="s">&quot;EP&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">FITC_EP</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible inf values are &quot;Laplace&quot;, &quot;EP&quot;.&#39;</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">useLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">newLik</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another inference techinique other than default Gaussian likelihood.</span>

<span class="sd">        :param str newLik: &#39;Laplace&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newLik</span> <span class="o">==</span> <span class="s">&quot;Laplace&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Laplace</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">FITC_EP</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible lik values are &quot;Laplace&quot;.&#39;</span><span class="p">)</span>





<span class="k">class</span> <span class="nc">GPC_FITC</span><span class="p">(</span><span class="n">GP_FITC</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Model for Gaussian Process Classification FITC</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GPC_FITC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">Zero</span><span class="p">()</span>                        <span class="c"># default prior mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span> <span class="o">=</span> <span class="n">cov</span><span class="o">.</span><span class="n">RBF</span><span class="p">()</span>                           <span class="c"># default prior covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span> <span class="o">=</span> <span class="n">lik</span><span class="o">.</span><span class="n">Erf</span><span class="p">()</span>                           <span class="c"># erf liklihood</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">FITC_EP</span><span class="p">()</span>                       <span class="c"># default inference method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>                <span class="c"># default optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u</span> <span class="o">=</span> <span class="bp">None</span>                                      <span class="c"># no default inducing points</span>



    <span class="k">def</span> <span class="nf">setOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">min_threshold</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">meanRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">covRange</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likRange</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Overriding. Usage see base class pyGPs.gp.GP.setOptimizer</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">conf</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">num_restarts</span><span class="o">!=</span><span class="bp">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">min_threshold</span><span class="o">!=</span><span class="bp">None</span><span class="p">):</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">Optimization</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">random_init_conf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">covfunc</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">likfunc</span><span class="p">)</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">num_restarts</span> <span class="o">=</span> <span class="n">num_restarts</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">min_threshold</span> <span class="o">=</span> <span class="n">min_threshold</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">meanRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">meanRange</span> <span class="o">=</span> <span class="n">meanRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">covRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">covRange</span> <span class="o">=</span> <span class="n">covRange</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">likRange</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">likRange</span> <span class="o">=</span> <span class="n">likRange</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;Minimize&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;SCG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">SCG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;CG&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">CG</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&quot;BFGS&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">BFGS</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conf</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">axisvals</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Plot 2d GP FITC classification.</span>
<span class="sd">        For plotting, we superimpose the data points with the posterior equi-probability contour </span>
<span class="sd">        lines for the probability of class two given complete information about the generating mechanism.</span>

<span class="sd">        :param x1: inputs for class +1</span>
<span class="sd">        :param x2: inputs for class -1</span>
<span class="sd">        :param t1: meshgrid array for the first axis</span>
<span class="sd">        :param t2: meshgrid array for the second axis</span>
<span class="sd">        :param list axisvals: [min_x, max_x, min_y, max_y] setting the plot range</span>

<span class="sd">        Note these parameters are (only) used for our hard-coded data for classification demo.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;b+&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">x2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;r+&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">pc</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lp</span><span class="p">),</span> <span class="p">(</span><span class="n">t1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">t1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="p">))</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pc</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">axisvals</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="n">axisvals</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>



    <span class="k">def</span> <span class="nf">useInference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">newInf</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another inference techinique other than default exact inference.</span>

<span class="sd">        :param str newInf: &#39;Laplace&#39; or &#39;EP&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newInf</span> <span class="o">==</span> <span class="s">&quot;Laplace&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inffunc</span> <span class="o">=</span> <span class="n">inf</span><span class="o">.</span><span class="n">FITC_Laplace</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible inf values are &quot;Laplace&quot;.&#39;</span><span class="p">)</span>



    <span class="k">def</span> <span class="nf">useLikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">newLik</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Use another inference techinique other than default Erf likelihood.</span>
<span class="sd">        (Not used in this version)</span>

<span class="sd">        :param str newLik: &#39;Logistic&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">newLik</span> <span class="o">==</span> <span class="s">&quot;Logistic&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&quot;Logistic likelihood is currently not implemented.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Possible lik values are &quot;Logistic&quot;.&#39;</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<h3><a href="../../../index.html">Table Of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Theory.html">GPs &amp; Functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Examples.html">Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Kernels.html">Kernels &amp; Means</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Likelihoods.html">Likelihoods &amp; Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Opts.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Develop.html">Developing Customized Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Graph.html">Kernels for Graph Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Default.html">List of Functions and Default Parameters</a></li>
</ul>

<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../../index.html">pyGPs v1.3.2 documentation</a> &raquo;</li>
          <li><a href="../../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Marion Neumann, Shan Huang, Daniel Marthaler, Kristian Kersting.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>
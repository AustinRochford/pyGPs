<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Semi-supervised Learning with Graphs &mdash; pyGPs v1.3.2 documentation</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'v1.3.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="pyGPs v1.3.2 documentation" href="index.html" />
    <link rel="up" title="Demos" href="Examples.html" />
    <link rel="next" title="Graph Kernels" href="GraphKernel.html" />
    <link rel="prev" title="Regression on UCI Housing data" href="demoHousing.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="GraphKernel.html" title="Graph Kernels"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="demoHousing.html" title="Regression on UCI Housing data"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">pyGPs v1.3.2 documentation</a> &raquo;</li>
          <li><a href="Examples.html" accesskey="U">Demos</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="semi-supervised-learning-with-graphs">
<h1>Semi-supervised Learning with Graphs<a class="headerlink" href="#semi-supervised-learning-with-graphs" title="Permalink to this headline">¶</a></h1>
<p>The code shown in this tutorial can be executed by running <em>pyGPs/Demo/demo_NodeKernel.py</em></p>
<div class="section" id="import">
<h2>Import<a class="headerlink" href="#import" title="Permalink to this headline">¶</a></h2>
<p>You may want to import some extensions we provide as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">pyGPs.GraphExtension</span> <span class="kn">import</span> <span class="n">graphUtil</span><span class="p">,</span> <span class="n">nodeKernels</span>
<span class="kn">from</span> <span class="nn">pyGPs.Validation</span> <span class="kn">import</span> <span class="n">valid</span>
</pre></div>
</div>
</div>
<div class="section" id="load-data">
<h2>Load data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h2>
<p>We used the same dataset from GPMC example. i.e. The USPS digits dataset <a class="footnote-reference" href="#id3" id="id1">[1]</a>.
Each digit of <img class="math" src="_images/math/634f30cffdb4731a6151074f964d0fa6b84cc288.png" alt="16*16"/> pixels is flattened into a <img class="math" src="_images/math/af847fb995302cbbcfa680c1a787a09a6f263753.png" alt="256"/> dimension vector.
For the simplicity of demo, we only selected digits <img class="math" src="_images/math/123e375e88da91240024aaf085abee194c4a2d06.png" alt="1"/> s and <img class="math" src="_images/math/15c663954a3e059d1f876bc8a4621de376038c96.png" alt="2"/> s such that we have a binary classification problem where digit <img class="math" src="_images/math/123e375e88da91240024aaf085abee194c4a2d06.png" alt="1"/> for class +1 and digit <img class="math" src="_images/math/15c663954a3e059d1f876bc8a4621de376038c96.png" alt="2"/> for class -1. We also reduced the dataset into <img class="math" src="_images/math/63e297a7a3a6ea37ad6b6bbf3f8ec35f5b1a3dba.png" alt="100"/> samples per digit, where the original dataset consist of thousands of samples for each digit.</p>
<p>Here are samples for two digits for <img class="math" src="_images/math/123e375e88da91240024aaf085abee194c4a2d06.png" alt="1"/></p>
<a class="reference internal image-reference" href="_images/digit1_1.png"><img alt="_images/digit1_1.png" src="_images/digit1_1.png" style="width: 30%;" /></a>
<a class="reference internal image-reference" href="_images/digit1_2.png"><img alt="_images/digit1_2.png" src="_images/digit1_2.png" style="width: 30%;" /></a>
<p>and samples for two digits for <img class="math" src="_images/math/15c663954a3e059d1f876bc8a4621de376038c96.png" alt="2"/></p>
<a class="reference internal image-reference" href="_images/digit2_1.png"><img alt="_images/digit2_1.png" src="_images/digit2_1.png" style="width: 30%;" /></a>
<a class="reference internal image-reference" href="_images/digit2_2.png"><img alt="_images/digit2_2.png" src="_images/digit2_2.png" style="width: 30%;" /></a>
</div>
<div class="section" id="form-a-nearest-neighbour-graph">
<h2>Form a nearest neighbour graph<a class="headerlink" href="#form-a-nearest-neighbour-graph" title="Permalink to this headline">¶</a></h2>
<p>We form a nearest-neighbor graph based on Euclidean distance of the vector representation of digits. Neighboring images have small Euclidean distance. Each digit is a node in the graph. There is an edge if digit <img class="math" src="_images/math/a581f053bbfa5115f42c13094857cdd12a37ec49.png" alt="i"/> is the k-nearest neighbour of digit <img class="math" src="_images/math/d32c78b759903e3f4bd4fd2ce0b86358f7500c5d.png" alt="j"/>. We form a symmetrized graph such that we connect nodes <img class="math" src="_images/math/d32c78b759903e3f4bd4fd2ce0b86358f7500c5d.png" alt="j"/>, <img class="math" src="_images/math/a581f053bbfa5115f42c13094857cdd12a37ec49.png" alt="i"/> if i is in j’s kNN and vice versa, and therefore a node can have more than k edges. You should import the corresponding module from <em>pyGPs.GraphStuff</em></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">load_binary</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="nb">reduce</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">graphUtil</span><span class="o">.</span><span class="n">formKnnGraph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>A is the adjacency matrix of this <img class="math" src="_images/math/17cc6db0cb2cbcda2f0aebfd92c16c77eba9ee5e.png" alt="2-NN"/> graph.</p>
<p>Below shows an example of such symmetrized Euclidean <img class="math" src="_images/math/17cc6db0cb2cbcda2f0aebfd92c16c77eba9ee5e.png" alt="2-NN"/> graph on some 1s and 2s taking from Xiaojin Zhu&#8217;s doctoral thesis <a class="footnote-reference" href="#id4" id="id2">[2]</a>.</p>
<div class="figure align-center">
<img alt="_images/2nnGraph.png" src="_images/2nnGraph.png" />
</div>
</div>
<div class="section" id="kernel-on-graph">
<h2>Kernel on graph<a class="headerlink" href="#kernel-on-graph" title="Permalink to this headline">¶</a></h2>
<p>Several classical kernels on graph described in <a class="reference external" href="Graph.html">Structured Kernels</a> can be built from adjacency matrix <img class="math" src="_images/math/0acafa529182e79b4f56165ec677554fba7fcf98.png" alt="A"/>. We use diffusion kernel for this example to get the precomputed kernel matrix.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">Matrix</span> <span class="o">=</span> <span class="n">nodeKernels</span><span class="o">.</span><span class="n">diffKernel</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
<p>This a big square matrix with all rows and columns of the number of data points.
By specifying the indice of training data and test data, we will form two matrix M1 and M2 with the exact format which <em>pyGPs.Core.cov.Pre</em> needed.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">M1</span><span class="p">,</span><span class="n">M2</span> <span class="o">=</span> <span class="n">graphUtil</span><span class="o">.</span><span class="n">formKernelMatrix</span><span class="p">(</span><span class="n">Matrix</span><span class="p">,</span> <span class="n">indice_train</span><span class="p">,</span> <span class="n">indice_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="docutils">
<dt>M1 is a matrix with shape <strong>number of training points plus 1</strong> by <strong>number of test points</strong></dt>
<dd><ul class="first last simple">
<li>cross covariances matrix (train by test)</li>
<li>last row is self covariances (diagonal of test by test)</li>
</ul>
</dd>
<dt>M2 is a square matrix with <strong>number of training points</strong> for each dimension</dt>
<dd><ul class="first last simple">
<li>training set covariance matrix (train by train)</li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="gp-classification">
<h2>GP classification<a class="headerlink" href="#gp-classification" title="Permalink to this headline">¶</a></h2>
<p>Every ingredients for a basic semi-supervised learning is prepared now.  Lets see how to proceed for <img class="math" src="_images/math/bc008ec23119a8f24d723e0616fee9a6f9a87cd2.png" alt="GP"/> classification. First, the normal way with rbf kernel we have seen several times</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">GPC</span><span class="p">()</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">cov</span><span class="o">.</span><span class="n">RBF</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setPrior</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>Then lets use our kernel precomputed matrix. If you only use precomputed kernel matrix, there is no training data.
However you still need to specify <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> just to fit in the usage of pyGPs for generality reason.
You can create any <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> as long as the dimension is correct.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">cov</span><span class="o">.</span><span class="n">Pre</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span><span class="n">M2</span><span class="p">)</span> <span class="o">+</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">cov</span><span class="o">.</span><span class="n">RBF</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setPrior</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>Moreover, you can composite a kernel for both precomputed matrix and regular kernel function if necessary.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">k</span> <span class="o">=</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">cov</span><span class="o">.</span><span class="n">Pre</span><span class="p">(</span><span class="n">M1</span><span class="p">,</span><span class="n">M2</span><span class="p">)</span> <span class="o">+</span> <span class="n">pyGPs</span><span class="o">.</span><span class="n">cov</span><span class="o">.</span><span class="n">RBFunit</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setPrior</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>The rest way of using pyGPs is exactly the same as the demo of GP classification.</p>
</div>
<div class="section" id="result">
<h2>Result<a class="headerlink" href="#result" title="Permalink to this headline">¶</a></h2>
<p>For our manually created graph data, an rbf kernel works better than a diffusion kernel on the graph (higher accuracy). The performance in general should depend on the application as well as features of data.</p>
<p>The left image shows the digit that using diffusion kernel will predict the wrong result (should be <img class="math" src="_images/math/15c663954a3e059d1f876bc8a4621de376038c96.png" alt="2"/>),
but rbf kernel does the job fine. The right image shows the digit that rbf kernel predicts the wrong class, diffusion kernel on the other hand, predicts correctly due to graph information! (should be <img class="math" src="_images/math/123e375e88da91240024aaf085abee194c4a2d06.png" alt="1"/>).</p>
<p>Interestingly, using a composite kernel with diffusion kernel on graph and an rbf kernel together. All test cases including the following are predicted correctly.</p>
<a class="reference internal image-reference" href="_images/digitDiffwrong.png"><img alt="_images/digitDiffwrong.png" src="_images/digitDiffwrong.png" style="width: 50%;" /></a>
<a class="reference internal image-reference" href="_images/digitRBFwrong.png"><img alt="_images/digitRBFwrong.png" src="_images/digitRBFwrong.png" style="width: 50%;" /></a>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>A Database for Handwritten Text Recognition Research, J. J. Hull, IEEE PAMI 16(5) 550-554, 1994.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>Semi-Supervised Learning with Graphs, Xiaojin Zhu, CMU-LTI-05-192, 2005</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<h3><a href="index.html">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory.html">GPs &amp; Functionality</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="Examples.html">Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="Kernels.html">Kernels &amp; Means</a></li>
<li class="toctree-l1"><a class="reference internal" href="Likelihoods.html">Likelihoods &amp; Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="Opts.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="Develop.html">Developing Customized Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Graph.html">Kernels for Graph Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Default.html">List of Functions and Default Parameters</a></li>
</ul>

  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/SemiSupervised.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="GraphKernel.html" title="Graph Kernels"
             >next</a> |</li>
        <li class="right" >
          <a href="demoHousing.html" title="Regression on UCI Housing data"
             >previous</a> |</li>
        <li><a href="index.html">pyGPs v1.3.2 documentation</a> &raquo;</li>
          <li><a href="Examples.html" >Demos</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Marion Neumann, Shan Huang, Daniel Marthaler, Kristian Kersting.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>